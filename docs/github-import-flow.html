<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>PowerGit GitHub Import Happy Path</title>
    <style>
      :root {
        color-scheme: light dark;
        font-family: system-ui, -apple-system, Segoe UI, sans-serif;
      }
      body {
        max-width: 1400px;
        margin: 2rem auto;
        padding: 0 1.5rem 4rem;
        line-height: 1.6;
        min-height: 100vh;
      }
      h1,
      h2,
      h3 {
        line-height: 1.3;
      }
      pre {
        background: rgba(0, 0, 0, 0.05);
        padding: 1rem 1.25rem;
        border-radius: 12px;
        overflow-x: auto;
        font-size: 1rem;
      }
      .diagram {
        margin: 2rem 0;
      }
      .diagram pre {
        font-size: 1.3rem;
      }
    </style>
    <script type="module">
      import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs";
      mermaid.initialize({
        startOnLoad: true,
        theme: "neutral",
        themeVariables: {
          fontSize: "20px",
          fontFamily: "system-ui, -apple-system, Segoe UI, sans-serif",
        },
      });
    </script>
  </head>
  <body>
    <h1>GitHub Explorer – Happy Path Flow</h1>
    <p>
      This document sketches the ideal end-to-end flow when a developer explores a GitHub repository
      in the PowerGit explorer UI. It highlights where cloning happens (Supabase Function + daemon),
      how the CLI/daemon participate, and where data gets cached so subsequent views stay fast and
      offline-ready.
    </p>

    <h2>High-Level Flow (shared clone worker)</h2>
    <p>
      Both diagrams share the same middle “Clone Worker” box:
    </p>
    <ul>
      <li><strong>Hosted mode:</strong> Supabase Edge Function executes the <code>psgit</code> workflow and uses the PowerSync remote helper to upload data to Supabase.</li>
      <li><strong>Offline mode:</strong> Local daemon runs the identical script; only the execution environment changes.</li>
    </ul>
    <p>
      The explorer calls a single import worker. In hosted mode that worker is a Supabase Edge
      Function; in local mode the daemon runs the same <code>psgit</code> steps. Everything downstream
      is identical.
    </p>
    <div class="diagram">
      <pre class="mermaid" style="min-height: 540px;">
sequenceDiagram
    autonumber
    participant User as Developer
    participant Explorer as Explorer UI
    participant Worker as Clone Worker<br/><small>Supabase Edge Function or Local Daemon</small>
    participant GitHub as GitHub Repo
    participant Storage as Supabase Storage
    participant DB as Supabase Postgres
    participant PSSvc as PowerSync Service

    User->>Explorer: Choose org/repo in UI
    Explorer->>Worker: invokeImport(repoUrl, orgId, repoId)
    Worker->>GitHub: Clone via psgit
    Worker->>Storage: Upload packfiles (git-remote-powersync)
    Worker->>DB: Upsert refs/commits/file_changes/objects
    Worker-->>Explorer: Return import summary
    DB-->>PSSvc: Publish raw-table changes (Sync Streams)
    PSSvc-->>Explorer: Stream updates (PowerSync Web)
    Explorer-->>User: Render branches/commits/files (TanStack DB)
      </pre>
    </div>

    <h2>Why “psgit” Exists</h2>
    <p>
      <code>psgit</code> is our thin CLI layer around git. It bundles three responsibilities:
    </p>
    <ul>
      <li><strong>Bootstrap Git repos:</strong> clone from GitHub and inject the <code>powersync::</code> remote helper so every future push streams packs + metadata into Supabase.</li>
      <li><strong>Orchestrate imports:</strong> handle auth, launch the daemon (if needed), invoke the clone worker (edge function or local), and poll until refs/commits land.</li>
      <li><strong>Keep CLI/daemon/explorer in sync:</strong> use PowerSync’s raw tables for all Git plumbing commands so the CLI, daemon, and explorer share one cached dataset.</li>
    </ul>
    <p>
      Without <code>psgit</code> we’d have to reimplement the Git protocol ourselves or manually upload packfiles and parse refs—which is brittle and hard to maintain. The remote helper piggybacks on git’s own pack negotiation while giving PowerSync the tidy raw-table representation it expects.
    </p>

    <h2>Remote Helper Details</h2>
    <table>
      <thead>
        <tr>
          <th>Stage</th>
          <th>Git command</th>
          <th>Remote helper behaviour</th>
          <th>Destination</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Clone</td>
          <td><code>psgit clone git@github.com:org/repo.git</code></td>
          <td>Helper reads packs from GitHub, streams them to the worker.</td>
          <td>Worker local filesystem</td>
        </tr>
        <tr>
          <td>Set PowerSync remote</td>
          <td><code>git remote add powersync powersync::https://...</code></td>
          <td>Helper swizzles Git transport, wrapping PowerSync APIs.</td>
          <td>N/A (configuration step)</td>
        </tr>
        <tr>
          <td>Push objects</td>
          <td><code>git push powersync --all --tags</code></td>
          <td>Helper uploads pack bytes, returning their OIDs.</td>
          <td>Supabase Storage <em>or</em> direct PowerSync blob store</td>
        </tr>
        <tr>
          <td>Publish metadata</td>
          <td>Helper internal call</td>
          <td>Helper emits refs/commits/file_changes rows to Supabase/Postgres.</td>
          <td>PowerSync raw tables (Supabase Postgres)</td>
        </tr>
      </tbody>
    </table>
    <p><em>Note:</em> The custom git remote helper is the glue. By registering the <code>powersync::</code> remote it intercepts every push, uploads packs, and emits the raw-table metadata that feeds PowerSync.</p>
    <p><strong>What is psgit?</strong> It is our CLI wrapper around <code>git</code>; it configures the <code>powersync::</code> remote so the helper can stream pack bytes and emit raw-table metadata no matter where the clone runs.</p>

    <h2>Hosted Clone, Local Playback</h2>
    <p>
      In this variant the Supabase Edge Function performs the clone, but the local daemon is still
      responsible for replaying metadata into PowerSync and serving the explorer offline.
    </p>
    <div class="diagram">
      <pre class="mermaid" style="min-height: 520px;">
sequenceDiagram
    autonumber
    participant User as Developer
    participant Explorer as Explorer UI
    participant SupaFunc as Supabase Edge Function
    participant Daemon as Local Daemon
    participant GitHub as GitHub Repo
    participant PSSvc as PowerSync Service
    participant DB as Supabase Postgres

    User->>Explorer: Select repo
    Explorer->>SupaFunc: invokeImport (repoUrl,...)
    SupaFunc->>GitHub: Clone via psgit
    SupaFunc->>Daemon: Notify / deliver pack summary
    Daemon->>DB: Upsert refs/commits/file_changes/objects
    DB-->>PSSvc: Publish raw-table changes
    PSSvc-->>Explorer: Stream updates (PowerSync Web)
    Explorer-->>User: Show repo contents
      </pre>
    </div>

    <h2>Alternative Flow (direct Postgres blobs)</h2>
    <p>
      In smaller deployments we can skip object storage. The same worker still runs <code>psgit</code> to produce the git packs, but streams the bytes and metadata straight into Postgres instead of object storage.
    </p>
    <div class="diagram">
      <pre class="mermaid" style="min-height: 540px;">
sequenceDiagram
    autonumber
    participant User as Developer
    participant Explorer as Explorer UI
    participant Worker as Clone Worker<br/><small>Supabase Edge Function or Local Daemon</small>
    participant GitHub as GitHub Repo
    participant PSSvc as PowerSync Service
    participant DB as Supabase Postgres

    User->>Explorer: Choose org/repo in UI
    Explorer->>Worker: invokeImport(repoUrl, orgId, repoId)
    Worker->>GitHub: Clone via psgit
    Worker->>DB: Store pack bytes + metadata (raw tables)
    DB-->>PSSvc: Publish raw-table changes
    PSSvc-->>Explorer: Stream updates
    Explorer-->>User: Render branches/commits/files (TanStack DB)
      </pre>
    </div>

    <h2>10-Step Happy Path</h2>
    <ol>
      <li><strong>User action:</strong> Developer opens the explorer and selects a GitHub org/repo.</li>
      <li><strong>Bootstrap:</strong> Explorer ensures the daemon is running so the hosted or local worker can be used interchangeably.</li>
      <li><strong>Auth reuse:</strong> Explorer/daemon load the active PowerSync/Supabase profile so no fresh login is needed.</li>
      <li><strong>Import dispatch:</strong> Explorer calls the shared clone worker (Supabase Edge Function in hosted deployments, local daemon in offline mode).</li>
      <li><strong>Clone + push:</strong> The worker runs <code>psgit</code>, clones from GitHub, sets the PowerSync remote, and pushes. Packfiles flow into Supabase Storage automatically via the remote helper.</li>
      <li><strong>Control-plane writes:</strong> The same job upserts refs, commits, file_changes, and objects metadata into Supabase Postgres.</li>
      <li><strong>Sync Streams:</strong> PowerSync service notices the new rows and broadcasts them through the org/repo streams.</li>
      <li><strong>Daemon cache:</strong> The local daemon (if present) receives the stream, keeps its raw SQLite replica warm, and serves CLI requests from the same data.</li>
      <li><strong>Explorer cache:</strong> Explorer’s PowerSync Web client syncs the four raw tables into IndexedDB; TanStack DB runs live queries directly on that cache.</li>
      <li><strong>Read experience:</strong> User browses branches/commits/files instantly—even offline—while subsequent updates from GitHub flow through the same pipeline.</li>
    </ol>

    <h2>Component Responsibilities</h2>
    <ul>
      <li>
        <strong>Explorer UI</strong> – issues the import request, subscribes to the four org/repo
        streams (<code>refs</code>, <code>commits</code>, <code>file_changes</code>,
        <code>objects</code>) and uses TanStack DB to materialise live queries locally. No direct
        Git logic lives here.
      </li>
      <li>
        <strong>Local daemon</strong> – owns PowerSync Node, Supabase writer, and the import manager.
        It ensures that:
        <ol>
          <li>
            raw SQLite tables exist locally (by running the raw-table migration when the daemon
            starts),
          </li>
          <li>
            Supabase writer persists control-plane changes (refs/commits/...) upstream, and
          </li>
          <li>
            Sync Streams remain subscribed for the requested org/repo so the explorer (and CLI) stay
            in sync.
          </li>
        </ol>
      </li>
      <li>
        <strong>Supabase Edge Function</strong> (or daemon fallback) – clones the GitHub repository
        using <code>git-remote-powersync</code>, stores packfiles in Supabase Storage, and upserts
        metadata rows (refs/commits/file changes) into Postgres. It returns a summary so the daemon
        can confirm what changed.
      </li>
      <li>
        <strong>PowerSync Service</strong> – delivers the raw table changes to all subscribed
        clients (daemon, explorer, CLI) via Sync Streams.
      </li>
    </ul>

    <h2>Cache/Storage Layers</h2>
    <ul>
      <li>
        <strong>Supabase Storage</strong>: Authoritative store for Git packfiles. Re-cloning the same
        repository reuses these packs.
      </li>
      <li>
        <strong>Supabase Postgres</strong>: Authoritative control-plane data (refs, commits,
        file_changes, objects metadata). Protected by the same constraints/indexes used on the
        client.
      </li>
      <li>
        <strong>Daemon PowerSync SQLite</strong>: Raw-table replica for offline CLI/daemon
        operations. Contains the exact schema as Postgres.
      </li>
      <li>
        <strong>Explorer IndexedDB (via PowerSync Web)</strong>: Browser cache, enabling offline
        browsing and fast TanStack DB queries without re-fetching the world.
      </li>
    </ul>

    <h2>CLI Integration</h2>
    <p>
      The CLI uses the same daemon endpoints. When the developer runs
      <code>psgit demo-seed</code> or <code>psgit sync</code>, it:
    </p>
    <ol>
      <li>Ensures the daemon is authenticated (guest login, token refresh).</li>
      <li>
        Triggers the same import path (either via the daemon directly or the Supabase function).
      </li>
      <li>Waits for daemon counters (<code>refs</code>/<code>commits</code>) to go non-zero.</li>
      <li>
        Uses the raw-table replica in the daemon PowerSync database to execute Git plumbing
        commands locally.
      </li>
    </ol>

    <h2>Happy Path Summary</h2>
    <ol>
      <li>Developer authenticates (Supabase password → daemon guest token).</li>
      <li>
        Explorer requests an import; daemon enqueues it (cloud function clone or local fallback).
      </li>
      <li>
        Git objects/metadata flow into Supabase (Storage + Postgres). Supabase writer + Sync Streams
        push them back to the daemon, then onwards to the explorer.
      </li>
      <li>
        Explorer renders the repo instantly using its cached dataset; CLI and daemon share the same
        raw-table replica for any follow-up Git commands.
      </li>
      <li>
        Subsequent visits hit local cache first and only stream incremental changes.
      </li>
    </ol>
  </body>
</html>
